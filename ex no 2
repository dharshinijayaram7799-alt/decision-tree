import math
from collections import Counter, defaultdict

# -----------------------------
# Dataset: Play Tennis
# -----------------------------
data = [
    ({"Outlook": "Sunny", "Temperature": "Hot", "Humidity": "High", "Wind": "Weak"}, "No"),
    ({"Outlook": "Sunny", "Temperature": "Hot", "Humidity": "High", "Wind": "Strong"}, "No"),
    ({"Outlook": "Overcast", "Temperature": "Hot", "Humidity": "High", "Wind": "Weak"}, "Yes"),
    ({"Outlook": "Rain", "Temperature": "Mild", "Humidity": "High", "Wind": "Weak"}, "Yes"),
    ({"Outlook": "Rain", "Temperature": "Cool", "Humidity": "Normal", "Wind": "Weak"}, "Yes"),
    ({"Outlook": "Rain", "Temperature": "Cool", "Humidity": "Normal", "Wind": "Strong"}, "No"),
    ({"Outlook": "Overcast", "Temperature": "Cool", "Humidity": "Normal", "Wind": "Strong"}, "Yes"),
    ({"Outlook": "Sunny", "Temperature": "Mild", "Humidity": "High", "Wind": "Weak"}, "No"),
    ({"Outlook": "Sunny", "Temperature": "Cool", "Humidity": "Normal", "Wind": "Weak"}, "Yes"),
    ({"Outlook": "Rain", "Temperature": "Mild", "Humidity": "Normal", "Wind": "Weak"}, "Yes"),
    ({"Outlook": "Sunny", "Temperature": "Mild", "Humidity": "Normal", "Wind": "Strong"}, "Yes"),
    ({"Outlook": "Overcast", "Temperature": "Mild", "Humidity": "High", "Wind": "Strong"}, "Yes"),
    ({"Outlook": "Overcast", "Temperature": "Hot", "Humidity": "Normal", "Wind": "Weak"}, "Yes"),
    ({"Outlook": "Rain", "Temperature": "Mild", "Humidity": "High", "Wind": "Strong"}, "No")
]

# -----------------------------
# Entropy Calculation
# -----------------------------
def entropy(labels):
    total = len(labels)
    counts = Counter(labels)
    return -sum((count/total) * math.log2(count/total) for count in counts.values())

# -----------------------------
# Information Gain
# -----------------------------
def information_gain(data, attribute):
    total_entropy = entropy([label for _, label in data])
    values = defaultdict(list)

    for record, label in data:
        values[record[attribute]].append(label)

    weighted_entropy = sum(
        (len(subset)/len(data)) * entropy(subset)
        for subset in values.values()
    )

    return total_entropy - weighted_entropy

# -----------------------------
# ID3 Algorithm
# -----------------------------
def id3(data, attributes):
    labels = [label for _, label in data]

    # If all labels are the same
    if len(set(labels)) == 1:
        return labels[0]

    # If no attributes left
    if not attributes:
        return Counter(labels).most_common(1)[0][0]

    # Choose best attribute
    best_attr = max(attributes, key=lambda attr: information_gain(data, attr))
    tree = {best_attr: {}}

    for value in set(record[best_attr] for record, _ in data):
        subset = [(r, l) for r, l in data if r[best_attr] == value]
        remaining_attrs = [a for a in attributes if a != best_attr]
        tree[best_attr][value] = id3(subset, remaining_attrs)

    return tree

# -----------------------------
# Classification
# -----------------------------
def classify(tree, sample):
    if not isinstance(tree, dict):
        return tree

    attribute = next(iter(tree))
    value = sample.get(attribute)

    return classify(tree[attribute].get(value), sample)

# -----------------------------
# Build Decision Tree
# -----------------------------
attributes = list(data[0][0].keys())
decision_tree = id3(data, attributes)

print("Decision Tree:")
print(decision_tree)

# -----------------------------
# Classify New Sample
# -----------------------------
new_sample = {
    "Outlook": "Sunny",
    "Temperature": "Cool",
    "Humidity": "High",
    "Wind": "Strong"
}

result = classify(decision_tree, new_sample)
print("\nNew Sample Classification:", result)
